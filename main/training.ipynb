{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T14:02:09.992480Z",
     "iopub.status.busy": "2022-08-10T14:02:09.987693Z",
     "iopub.status.idle": "2022-08-10T14:02:12.872562Z",
     "shell.execute_reply": "2022-08-10T14:02:12.870819Z",
     "shell.execute_reply.started": "2022-08-10T14:02:09.991351Z"
    },
    "id": "oxiZ42B4SwQ-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tests_hw4 import test_prediction, test_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T14:02:12.888156Z",
     "iopub.status.busy": "2022-08-10T14:02:12.884281Z",
     "iopub.status.idle": "2022-08-10T14:02:12.960590Z",
     "shell.execute_reply": "2022-08-10T14:02:12.958805Z",
     "shell.execute_reply.started": "2022-08-10T14:02:12.888058Z"
    },
    "id": "x5znxQhLSwRC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load all that we need\n",
    "\n",
    "dataset = np.load('../dataset/wiki.train.npy', allow_pickle=True)\n",
    "devset = np.load('../dataset/wiki.valid.npy', allow_pickle=True)\n",
    "fixtures_pred = np.load('../fixtures/prediction.npz')  # dev\n",
    "fixtures_gen = np.load('../fixtures/generation.npy')  # dev\n",
    "fixtures_pred_test = np.load('../fixtures/prediction_test.npz')  # test\n",
    "fixtures_gen_test = np.load('../fixtures/generation_test.npy')  # test\n",
    "vocab = np.load('../dataset/vocab.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T14:02:12.976526Z",
     "iopub.status.busy": "2022-08-10T14:02:12.973129Z",
     "iopub.status.idle": "2022-08-10T14:02:13.075531Z",
     "shell.execute_reply": "2022-08-10T14:02:13.073088Z",
     "shell.execute_reply.started": "2022-08-10T14:02:12.976317Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T14:02:13.079390Z",
     "iopub.status.busy": "2022-08-10T14:02:13.078847Z",
     "iopub.status.idle": "2022-08-10T14:02:13.196189Z",
     "shell.execute_reply": "2022-08-10T14:02:13.192167Z",
     "shell.execute_reply.started": "2022-08-10T14:02:13.079324Z"
    },
    "id": "OZNrJ8XvSwRF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LanguageModelDataLoader(DataLoader):\n",
    "    \"\"\"\n",
    "        TODO: Define data loader logic here\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size, shuffle=True):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        # concatenate your articles and build into batches\n",
    "        # 1. Shuffle data\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.dataset)\n",
    "        # 2. Concatenate articles and drop extra words\n",
    "        new_dataset = np.concatenate(self.dataset)\n",
    "        num_batches = (len(new_dataset)-1) // self.batch_size\n",
    "        \n",
    "        window = num_batches*self.batch_size\n",
    "        # inputs\n",
    "        inputs = new_dataset[:window].reshape(self.batch_size, -1)\n",
    "        inputs = torch.LongTensor(inputs)\n",
    "        # targets\n",
    "        targets = new_dataset[1:window+1].reshape(self.batch_size, -1)\n",
    "        targets = torch.LongTensor(targets)\n",
    "        \n",
    "        batch_idx = 0\n",
    "        while batch_idx < num_batches:\n",
    "        # ======================================================\n",
    "        #                   adapted from paper\n",
    "        # Title: Regularizing and Optimizing LSTM Language Models\n",
    "        # Authors: \n",
    "        # - Stephen Merity\n",
    "        # - Nitish Shirish Keskar\n",
    "        # - Richard Socher\n",
    "        # Section 4.1: Variable length backpropagation sequences\n",
    "        # =======================================================\n",
    "            p = np.random.random_sample()\n",
    "            if p < 0.95:\n",
    "                self.seq_len = round(np.random.normal(25, 5))\n",
    "            else:\n",
    "                self.seq_len = round(np.random.normal(19, 5))\n",
    "            \n",
    "            # 3. batching\n",
    "            inp = inputs[:, batch_idx:batch_idx+self.seq_len].T\n",
    "            tgt = targets[:, batch_idx:batch_idx+self.seq_len].T\n",
    "            \n",
    "            # update batch index\n",
    "            batch_idx += self.seq_len\n",
    "            \n",
    "            # 4. return\n",
    "            yield inp, tgt # -->(seq_len, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T14:02:13.201209Z",
     "iopub.status.busy": "2022-08-10T14:02:13.199554Z",
     "iopub.status.idle": "2022-08-10T14:02:13.335574Z",
     "shell.execute_reply": "2022-08-10T14:02:13.333740Z",
     "shell.execute_reply.started": "2022-08-10T14:02:13.201127Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl = LanguageModelDataLoader(dataset=dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T14:02:13.338661Z",
     "iopub.status.busy": "2022-08-10T14:02:13.337960Z",
     "iopub.status.idle": "2022-08-10T14:02:13.435966Z",
     "shell.execute_reply": "2022-08-10T14:02:13.434098Z",
     "shell.execute_reply.started": "2022-08-10T14:02:13.338592Z"
    },
    "id": "Zt-7YsTYSwRI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "        TODO: Define your model here\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim:int=512, hidden_size:int=512, num_layers:int=3, bidir:bool=False):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # layers\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=self.embedding_dim)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=self.embedding_dim, \n",
    "            hidden_size=self.hidden_size, \n",
    "            num_layers=self.num_layers, \n",
    "            bidirectional=bidir, \n",
    "            batch_first=False\n",
    "        )\n",
    "        if bidir:\n",
    "            n = 2\n",
    "        else:\n",
    "            n = 1\n",
    "        self.decoder = nn.Linear(in_features=self.hidden_size* n, out_features=self.vocab_size)\n",
    "        self.decoder.weight = self.embedding.weight # weight tying\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # Feel free to add extra arguments to forward (like an argument to pass in the hiddens)\n",
    "        S, BS = x.size()\n",
    "        \n",
    "        out = self.embedding(x)\n",
    "        out = self.dropout(out)\n",
    "        out, hidden = self.encoder(out, hidden)\n",
    "        out = out.reshape(-1, self.hidden_size)\n",
    "        out = self.decoder(out)\n",
    "        # format output: ---> (seq_len, batch_size, vocab_size)\n",
    "        out = out.view(-1, BS, self.vocab_size)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T14:02:13.440820Z",
     "iopub.status.busy": "2022-08-10T14:02:13.440281Z",
     "iopub.status.idle": "2022-08-10T14:02:13.644455Z",
     "shell.execute_reply": "2022-08-10T14:02:13.642614Z",
     "shell.execute_reply.started": "2022-08-10T14:02:13.440752Z"
    },
    "id": "kIvZOIfjSwRK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model trainer\n",
    "\n",
    "class LanguageModelTrainer:\n",
    "    def __init__(self, model, loader, max_epochs=1, lr=3e-3, run_id='exp'):\n",
    "        \"\"\"\n",
    "            Use this class to train your model\n",
    "        \"\"\"\n",
    "        # feel free to add any other parameters here\n",
    "        self.model = model\n",
    "        self.loader = loader\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.predictions = []\n",
    "        self.predictions_test = []\n",
    "        self.generated_logits = []\n",
    "        self.generated = []\n",
    "        self.generated_logits_test = []\n",
    "        self.generated_test = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "        self.lr = lr\n",
    "        \n",
    "        # TODO: Define your optimizer and criterion here\n",
    "        self.optimizer = torch.optim.Adam(params=self.model.parameters(), weight_decay=1e-6, lr=self.lr) # adam is better with quite little lr\n",
    "        self.criterion = nn.CrossEntropyLoss().to(device)\n",
    "        self.scheduler = torch.optim.lr_scheduler.StepLR(optimizer=self.optimizer, step_size=1, gamma=.6)\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train() # set to training mode\n",
    "        self.model.to(device)\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_num, (inputs, targets) in enumerate(self.loader):\n",
    "            loss = self.train_batch(inputs, targets)\n",
    "            epoch_loss += loss\n",
    "        \n",
    "        epoch_loss = epoch_loss / (batch_num + 1)\n",
    "        self.epochs += 1\n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "        self.scheduler.step()\n",
    "\n",
    "    def train_batch(self, inputs, targets):\n",
    "        \"\"\" \n",
    "            TODO: Define code for training a single batch of inputs\n",
    "        \n",
    "        \"\"\"\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        out = self.model(inputs)\n",
    "        # format inputs to the loss function\n",
    "        out = out.view(-1, out.size(2))\n",
    "        targets = targets.contiguous().view(-1) # flatten targets\n",
    "        loss = self.criterion(out, targets)\n",
    "        \n",
    "        # backward pas\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "\n",
    "    \n",
    "    def test(self):\n",
    "        # don't change these\n",
    "        self.model.eval() # set to eval mode\n",
    "        predictions = TestLanguageModel.prediction(fixtures_pred['inp'], self.model) # get predictions\n",
    "        self.predictions.append(predictions)\n",
    "        generated_logits = TestLanguageModel.generation(fixtures_gen, 10, self.model) # generated predictions for 10 words\n",
    "        generated_logits_test = TestLanguageModel.generation(fixtures_gen_test, 10, self.model)\n",
    "        nll = test_prediction(predictions, fixtures_pred['out'])\n",
    "        generated = test_generation(fixtures_gen, generated_logits, vocab)\n",
    "        generated_test = test_generation(fixtures_gen_test, generated_logits_test, vocab)\n",
    "        self.val_losses.append(nll)\n",
    "        \n",
    "        self.generated.append(generated)\n",
    "        self.generated_test.append(generated_test)\n",
    "        self.generated_logits.append(generated_logits)\n",
    "        self.generated_logits_test.append(generated_logits_test)\n",
    "        \n",
    "        # generate predictions for test data\n",
    "        predictions_test = TestLanguageModel.prediction(fixtures_pred_test['inp'], self.model) # get predictions\n",
    "        self.predictions_test.append(predictions_test)\n",
    "            \n",
    "        print('[VAL]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs, self.max_epochs, nll))\n",
    "        return nll\n",
    "\n",
    "    def save(self):\n",
    "        # don't change these\n",
    "        model_path = os.path.join('experiments', self.run_id, 'model-{}.pkl'.format(self.epochs))\n",
    "        torch.save({'state_dict': self.model.state_dict()},\n",
    "            model_path)\n",
    "        np.save(os.path.join('experiments', self.run_id, 'predictions-{}.npy'.format(self.epochs)), self.predictions[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'predictions-test-{}.npy'.format(self.epochs)), self.predictions_test[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-{}.npy'.format(self.epochs)), self.generated_logits[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-test-{}.npy'.format(self.epochs)), self.generated_logits_test[-1])\n",
    "        with open(os.path.join('experiments', self.run_id, 'generated-{}.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(self.generated[-1])\n",
    "        with open(os.path.join('experiments', self.run_id, 'generated-{}-test.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(self.generated_test[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T14:02:13.650105Z",
     "iopub.status.busy": "2022-08-10T14:02:13.649526Z",
     "iopub.status.idle": "2022-08-10T14:02:13.848017Z",
     "shell.execute_reply": "2022-08-10T14:02:13.846424Z",
     "shell.execute_reply.started": "2022-08-10T14:02:13.650036Z"
    },
    "id": "xPI7_kZRSwRN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestLanguageModel:\n",
    "    def prediction(inp, model):\n",
    "        \"\"\"\n",
    "            TODO: write prediction code here\n",
    "            \n",
    "            :param inp:\n",
    "            :return: a np.ndarray of logits\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            inp = inp.T\n",
    "            inp = torch.tensor(inp).long().to(device)\n",
    "            out = model(inp)\n",
    "            pred = out[-1, :]\n",
    "        \n",
    "        return pred.detach().cpu().numpy()\n",
    "\n",
    "        \n",
    "    def generation(inp, forward, model):\n",
    "        \"\"\"\n",
    "            TODO: write generation code here\n",
    "\n",
    "            Generate a sequence of words given a starting sequence.\n",
    "            :param inp: Initial sequence of words (batch size, length)\n",
    "            :param forward: number of additional words to generate\n",
    "            :return: generated words (batch size, forward)\n",
    "        \"\"\"        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            inp = torch.tensor(inp).long().to(device)\n",
    "            for _ in range(forward):\n",
    "                fwd_input = inp.permute(1, 0)\n",
    "                # prediction\n",
    "                out = model(fwd_input)[-1, :]\n",
    "                word = torch.argmax(out, dim=1, keepdim=True)\n",
    "                inp = torch.cat((inp, word), dim=1) # add pred to all predicions\n",
    "            words = inp[:, -forward:] # keep last perdicted words\n",
    "        return words.detach().cpu().numpy()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T14:02:13.852171Z",
     "iopub.status.busy": "2022-08-10T14:02:13.850633Z",
     "iopub.status.idle": "2022-08-10T14:02:13.927227Z",
     "shell.execute_reply": "2022-08-10T14:02:13.924500Z",
     "shell.execute_reply.started": "2022-08-10T14:02:13.852093Z"
    },
    "id": "TiUrjbEjSwRQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: define other hyperparameters here\n",
    "\n",
    "NUM_EPOCHS = 8\n",
    "BATCH_SIZE = 128\n",
    "LR = 4e-3\n",
    "EMB_DIM = 350\n",
    "HIDDEN_SIZE = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T14:02:13.931258Z",
     "iopub.status.busy": "2022-08-10T14:02:13.930204Z",
     "iopub.status.idle": "2022-08-10T14:02:14.107883Z",
     "shell.execute_reply": "2022-08-10T14:02:14.105987Z",
     "shell.execute_reply.started": "2022-08-10T14:02:13.931185Z"
    },
    "id": "2HCVG5YISwRW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models, predictions, and generated words to ./experiments/1660140134\n"
     ]
    }
   ],
   "source": [
    "run_id = str(int(time.time()))\n",
    "if not os.path.exists('./experiments'):\n",
    "    os.mkdir('./experiments')\n",
    "os.mkdir('./experiments/%s' % run_id)\n",
    "print(\"Saving models, predictions, and generated words to ./experiments/%s\" % run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T14:02:14.110787Z",
     "iopub.status.busy": "2022-08-10T14:02:14.109778Z",
     "iopub.status.idle": "2022-08-10T14:02:14.929087Z",
     "shell.execute_reply": "2022-08-10T14:02:14.925078Z",
     "shell.execute_reply.started": "2022-08-10T14:02:14.110707Z"
    },
    "id": "DbHH6zXTSwRa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LanguageModel(len(vocab), embedding_dim=EMB_DIM, hidden_size=HIDDEN_SIZE)\n",
    "loader = LanguageModelDataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "trainer = LanguageModelTrainer(model=model, loader=loader, max_epochs=NUM_EPOCHS, run_id=run_id, lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T14:02:14.932325Z",
     "iopub.status.busy": "2022-08-10T14:02:14.931775Z",
     "iopub.status.idle": "2022-08-10T14:35:37.109021Z",
     "shell.execute_reply": "2022-08-10T14:35:37.107016Z",
     "shell.execute_reply.started": "2022-08-10T14:02:14.932256Z"
    },
    "id": "7D8wTJkBSwRc",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [2/8]   Loss: 6.2864\n",
      "[VAL]  Epoch [1/8]   Loss: 4.9540\n",
      "Saving model, predictions and generated output for epoch 0 with NLL: 4.953958\n",
      "[TRAIN]  Epoch [3/8]   Loss: 5.4123\n",
      "[VAL]  Epoch [2/8]   Loss: 4.5906\n",
      "Saving model, predictions and generated output for epoch 1 with NLL: 4.590621\n",
      "[TRAIN]  Epoch [4/8]   Loss: 5.0944\n",
      "[VAL]  Epoch [3/8]   Loss: 4.4269\n",
      "Saving model, predictions and generated output for epoch 2 with NLL: 4.4269104\n",
      "[TRAIN]  Epoch [5/8]   Loss: 4.8970\n",
      "[VAL]  Epoch [4/8]   Loss: 4.4632\n",
      "[TRAIN]  Epoch [6/8]   Loss: 4.7561\n",
      "[VAL]  Epoch [5/8]   Loss: 4.4534\n",
      "[TRAIN]  Epoch [7/8]   Loss: 4.6664\n",
      "[VAL]  Epoch [6/8]   Loss: 4.4704\n",
      "[TRAIN]  Epoch [8/8]   Loss: 4.6002\n",
      "[VAL]  Epoch [7/8]   Loss: 4.4910\n",
      "[TRAIN]  Epoch [9/8]   Loss: 4.5668\n",
      "[VAL]  Epoch [8/8]   Loss: 4.5118\n"
     ]
    }
   ],
   "source": [
    "best_nll = 1e30 \n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    trainer.train()\n",
    "    nll = trainer.test()\n",
    "    if nll < best_nll:\n",
    "        best_nll = nll\n",
    "        print(\"Saving model, predictions and generated output for epoch \"+str(epoch+1)+\" with NLL: \"+ str(best_nll))\n",
    "        trainer.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T14:35:37.115762Z",
     "iopub.status.busy": "2022-08-10T14:35:37.115177Z",
     "iopub.status.idle": "2022-08-10T14:35:37.619178Z",
     "shell.execute_reply": "2022-08-10T14:35:37.617380Z",
     "shell.execute_reply.started": "2022-08-10T14:35:37.115691Z"
    },
    "id": "z2FmDqBCSwRf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Don't change these\n",
    "# plot training curves\n",
    "plt.figure()\n",
    "plt.plot(range(1, trainer.epochs + 1), trainer.train_losses, label='Training losses')\n",
    "plt.plot(range(1, trainer.epochs + 1), trainer.val_losses, label='Validation losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('NLL')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T14:35:37.623322Z",
     "iopub.status.busy": "2022-08-10T14:35:37.622215Z",
     "iopub.status.idle": "2022-08-10T14:35:37.632729Z",
     "shell.execute_reply": "2022-08-10T14:35:37.631118Z",
     "shell.execute_reply.started": "2022-08-10T14:35:37.623242Z"
    },
    "id": "ipdbmqaGSwRh",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input | Output #0: while the group was en route , but only three were ultimately able to attack . None of them were | also used to attack the <unk> , which had been\n",
      "Input | Output #1: <unk> , where he remained on loan until 30 June 2010 . <eol> = = = Return to Manchester United | = = = <eol> On July 7 , 2009 ,\n",
      "Input | Output #2: 25 April 2013 , denoting shipments of 500 @,@ 000 copies . <eol> The song became One Direction 's fourth | single , \" Best <unk> \" , and \" <unk>\n",
      "Input | Output #3: , and Bruce R. ) one daughter ( Wendy J. <unk> ) and two grandchildren , died in <unk> , | and the <unk> of the <unk> , the <unk> ,\n",
      "Input | Output #4: Warrior were examples of this type . Because their armor was so heavy , they could only carry a single | <unk> . The first time the ship had been damaged\n",
      "Input | Output #5: the embassy at 1 : 49 and landed on Guam at 2 : 23 ; twenty minutes later , Ambassador | <unk> <unk> ( <unk> ) , <unk> ( <unk> )\n",
      "Input | Output #6: <unk> , $ 96 million USD ) . Damage was heaviest in South Korea , notably where it moved ashore | . The storm moved to the west and then north\n",
      "Input | Output #7: The <unk> were condemned as <unk> by <unk> , who saw the riots as hampering attempts to resolve the situation | . <eol> = = = = <unk> = = =\n",
      "Input | Output #8: by a decision made by the War Office in mid @-@ 1941 , as it was considering the equipment to | the public . The new company had been established by\n",
      "Input | Output #9: Division crossed the <unk> at a number of places and climbed the hills quietly toward the 9th Infantry river line | . The ship was completed in December , and the\n",
      "Input | Output #10: = <eol> = = = French VIII . Corps ( Corps <unk> ) = = = <eol> On 6 November | , the German and Ottoman force of <unk> was transferred\n",
      "Input | Output #11: of the World from 9th Avenue \" . This is regarded as his most famous work . It is considered | the most popular of the world 's most popular characters\n",
      "Input | Output #12: — <unk> @-@ 10 , <unk> @-@ 12 , <unk> @-@ 16 , <unk> @-@ 17 — were all converted | into a <unk> . <eol> = = = = <unk>\n",
      "Input | Output #13: And now he has . \" <eol> = = Family = = <eol> <unk> lived 37 of his years in | the first half of the 20th century , and was\n",
      "Input | Output #14: Hell to which he has been condemned for <unk> . Eliot , in a letter to John <unk> dated 27 | June , he was appointed as a member of the\n",
      "Input | Output #15: Luoyang area , fulfilling his duties in domestic affairs . <eol> In the autumn of <unk> , he met Li | <unk> and his wife , and his wife , <unk>\n",
      "Input | Output #16: Power said they enjoyed Block Ball and its number of stages , but wondered how its eight <unk> of memory | . \" <eol> = = = <unk> = = =\n",
      "Input | Output #17: by Lloyd F. Lonergan . The cameraman was Jacques <unk> . <eol> = = Release and reception = = <eol> | The episode was written by <unk> <unk> , who was\n",
      "Input | Output #18: alone , the Austrians lost more than half their reserve artillery park , 6 @,@ 000 ( out of 8 | @,@ 000 ) and a pair of <unk> . <eol>\n",
      "Input | Output #19: while attacking a ship at <unk> in the Dutch East Indies ; the loss was compounded by the fact that | the ship was not able to withdraw . <eol> =\n",
      "Input | Output #20: first raised in 2007 by the member of parliament ( MP ) for <unk> . The gangsters may have run | the <unk> of the <unk> , and the <unk> of\n",
      "Input | Output #21: Species are also non @-@ spiny <unk> and includes both large trees with stout stems up to 30 metres ( | 39 ft ) . The <unk> is a <unk> <unk>\n",
      "Input | Output #22: \" : specific design issues with the building 's energy efficiency included the fact that the largest room in the | world is the largest , most commonly known as the\n",
      "Input | Output #23: were reported to support over 300 @,@ 000 households in the Brazilian state of <unk> in 2005 , and in | the United States , the United States , the United\n",
      "Input | Output #24: port . <unk> in Vietnam also warned for the potential of heavy rainfall due to the dissipating Tropical Depression <unk> | , but the storm was not as the result of\n",
      "Input | Output #25: T @-@ numbers in their tropical cyclone products . The following example is from discussion number 3 of Tropical Depression | One @-@ E formed on July 10 . The depression\n",
      "Input | Output #26: South Australia hosted the three @-@ game semi @-@ final series against the New South Wales <unk> . Both teams | were the first to win the Championship in the Football\n",
      "Input | Output #27: Perth from contention and secured the last finals spot for the <unk> . <eol> = = = Statistical leaders = | = = <eol> In the United States , the player\n",
      "Input | Output #28: deemed it an \" amazing pop song \" , lauding the group 's falsetto and its \" head @-@ <unk> | \" . The song was written by <unk> <unk> ,\n",
      "Input | Output #29: , but began patrolling the English Channel after <unk> @-@ 6 pioneered a route past British <unk> nets and mines | . <eol> = = = <unk> = = = <eol>\n",
      "Input | Output #30: production executives to let him direct . He had already discussed the film with <unk> and Cohen , and felt | that the episode was \" <unk> \" . <eol> =\n",
      "Input | Output #31: and Nick <unk> at Studio <unk> in Los Angeles , California , and was released on August 1 , 2006 | . The episode was written by <unk> <unk> and directed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see generated output\n",
    "print (trainer.generated[-1]) # get last generated output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "4df2cc69eb3fd56a8a9780b07025dcfa15673fb6f5e64f079d5772d6ef5f08ae"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
